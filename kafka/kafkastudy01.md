# Apache kafka : 분산 메세징 시스템

대량의 데이터를 **높은 처리량**과 **실시간**으로 처리하기 위한 제품이다.

* 확장성 (여러 서버로 구성- Scale 관리 가능)
* 영속성  (수신한 데이터를 디스크에 유지 - 언제라도 데이터 읽기 가능)
* 유연성 (연계가능한 제품 多, Hub 역할 가능)
* 신뢰성 (전달 **보증**을 하므로 분실 걱정 X)

Kafka 이전 문제점

* #### 메세지 큐
  * 강력한 전달 보증 → 오버스펙인데..
    * 전달 보증보다는 처리 위주로...

  * Scale out 해야되는데...
    * 서버가 1대로는 안될텐데??
  * 메시지가 대량으로 쌓일건데??
    * 데이터가 축적될 수는 있으나 kafka는 **kafka as a storage**를 내세움. 즉, 스토리지 시스템.

* #### 로그 수집 시스템

  * HDFS(Hadoop Distributed File System)로 데이터 축적과 배치 처리만 고려했다고??
    * *Hadoop : 대용량 데이터를 분산 처리할 수 있는 Java 기반의 오픈 소스 프레임워크
    * *HDFS : 대용량 파일을 **분산 서버**에 저장 후, 저장된 데이터를 빠르게 처리할 수 있게 하는 파일 시스템
    * 이것들을 Hadoop에 맞게 다시 짜라고??
  * 알기 쉬운 API가 없네..
    * 아니 미들웨어까지 다 까뒤집어서 내가 써야해???
  * 수신하는 쪽이 임의로 메시지 수신이 어렵다.
    * 수신하고 일도 좀 해놓고 메시지를 받아야지 막 주면 되나;
    * push : 말그대로 메세지를 밀어버리는것. 일단 주고본다... 이런 느낌?
    * pull : 알아서 가져가세유~

* #### ETL 도구 (ETL : Extract , Transform, Load)

  * 데이터를 파일 단위로 다루네?
    * 한 건 단위로 하면 안돼??
  * 수신하는 쪽이 임의로 메시지를 수신하기 어렵네?
    * ETL은 데이터를 추출, 변환하여 다른 데이터 저장소에 전달하는 것을 주축으로함.

#### → 이 모든 것들이 맞물려서 직접 만들기로 결정

#### 그들이 바랐던 것....

1. 높은 처리량으로 실시간 처리
2. 임의의 타이밍에 데이터 읽기
3. 다양한 제품과 시스템에 쉽게 연동
4. 메시지를 잃지 않을 것

#### 이 들을 구현하기 위해

1. 메시징 모델 + Scale out 형 아키텍쳐
2. 디스크로의 데이터 영속화
3. 이해하기 쉬운 API 제공
4. 전달 보증



### 메시징 모델과 Scale out

그들이 바랐던 1, 2, 3번을 해결하기 위해 도입한 메시징 모델

**Producer** : 메시지 생산자

**Broker** : 메시지 수집/전달 역할

**Consumer** : 메시지 소비자

Producer에서 생산한 메시지를 Broker가 수집하고, 이를 Consumer에게 전달

이를 위한 구조로 2가지 구조가 있다. **Queuing(큐잉) 모델** 과 **Publish/Subscribe(Pub펍/Sub섭)** 모델

#### Queueing Model

**Broker**내부에 Queue를 준비하고, **Producer**에서 메시지를 쏘면 Queue에 담긴다. 그걸 **Consumer**가 빼가는것. 이러면 Consumer가 메시지를 빼가니까 Consumer를 여러개 준비하면 처리를 늘릴 수 있다.

#### Pub/Sub Model

Pub : Producer , Sub : Consumer 이라고 하자. Pub이 Sub한테 바로 메시지를 쏘는게 아니라, Broker한테 주고 끝. 누가 가져가는지는 알게뭐야. 대신 이상한 Sub가 가져가면 안되니까 **Topic**이라는 카테고리 안에 등록.

Sub는 듣고싶은 Topic만 골라서 들어서 가져간다. **같은 토픽을 구독하는 여러 Sub에게는 동일한 메시지가 전달됨.** 

#### 이 짓을 왜 하나?

단순히 생각해보면, 이런 시스템을 구축하려면 Broker 없이 그냥 구축하면 Producer N개, Consumer M개가 있으면 N*M개의 edge가 필요한데, Broker을 중간에 끼워버리면 N+M개의 edge면 뚝딱.

거기다가 Producer을 늘리면 전자의 경우에는 M개의 edge가 더 필요하고, Consumer를 늘리면 N개의 edge가 더 필요한데 Broker을 끼우면 1개씩만 늘리면 되서 복잡하지 않음.

#### kafka의 메시징 모델

위의 이런 장점을을 실현하기 위해 **Consumer Group**이라는 개념을 도입. 여러 Consumer가 Topic을 분산하여 메시지를 읽는다.

거기에 Broker마저 복수 구성을 할 수 있게 해둬서 Scale out에 굉장히 용이함.



### 디스크로의 데이터 영속화

1. 임의의 타이밍에 데이터 읽기
2. 메시지 잃지 않기 (고장 손실용 X)

를 위해서, kafka는 디스크에서 영속화를 하는데, 높은 처리량까지 제공.

이런 이유로 kafka를 스토리지 시스템처럼 간주할 수 있음.



### 이해하기 쉬운 API 제공

* 다양한 제품과 시스템에 쉽게 연동하기

이를 위해, Producer, Consumer에 쉽게 접속하기 위한 Connect API 제공.

API 기반으로 kafka에 접속하기 위해 kafka Connect도 제공.

kafka connect (Producer/Consumer)에 접속하기 위한 **Connector** 플러그인이 개발되어져 있어 외부 시스템과 접속할 수 있음.

**Streams API**(kafka에 있는 데이터를 Stream처리하는 API)를 라이브러리화 한 Kafka Streams라는 클라이언트 라이브러리를 사용하면 Stream처리 Application을 쉽게 구현할 수 있음.



### 전달 보증

* 메시지를 잃지 않는다!!

이를 위한 3가지 전달 보증 수준

1. At Most Once (1번까지는 전달 **시도**할게...) - 재전송X, 중복삭제X
   * 중복되지는 않는데  사라질 수도 있음 ㅅㄱ
2. At Least Once (1번은 꼭 전달 할게!!) - 재전송O, 중복삭제X
   * 중복될 수는 있는데 그래도 사라지지는 않아여 ㅎ..ㅎ...
3. Exactly Once (**정.확.히** 1번. 전.달.한.다) - 재전송O, 중복삭제O
   * 중복, 상실. 그런거 없다. 정.확. 그자체. 근데 성능이.. 안나오네 ㅋ0ㅋ

#### At Least Once를 위한 구현

1. Producer와 Broker

Producer : 옛다 메시지

Broker : 수신완료!! ACK!!!

*정상 수신 시 ACK를 반환한다는 뜻.

2. Consumer와 Broker

Broker : 메시지 받아가세유~

Consumer : 정상처리되었습니다(Offset Commit).

*수신 정상 처리 시 수신완료 기록을 Broker에 남긴다는 뜻

#### Exactly Once를 위한 구현

1. Producer와 Broker (상류 시스템)

P : 옛다 메시지~

B : (일단 받은 메시지를 써둠) ACK!!!(전송 안됨)

P : (아니 ACK ㅇㄷ감? 메시지 못받은거 아녀?) 옛다 아까 그 메시지~

B : (아니 아까온 메시진데? 제낀다. 그래도 받았으니 받았다고는 해야지) ACK!!!(전송됨)

2. Consumer와 Broker (하류 시스템)

C : 트랜잭션 해주세요.

B : 트랜잭션 했음. 메세지 받아가슈

C : (메시지 처리함) 처리 결과 여깄어요.

C : 정상 처리했구요.

C : 아, 트랜잭션 Abort/Timeout할게염 ㅈㅅㅋㅋ

B : (XX) 무슨일 있었어요? (트랜잭션 후 했던 일이 없어진것 처럼)



### 기업이 많이 쓴대요... 네...





